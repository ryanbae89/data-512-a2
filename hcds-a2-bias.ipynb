{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 512 Assignment 2: Bias in Data\n",
    "\n",
    "DATA 512 Fall 2018\n",
    "\n",
    "Ryan Bae\n",
    "\n",
    "Due: November 1st, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "page_data = pd.read_csv('page_data.csv')\n",
    "wpds_2018 = pd.read_csv('WPDS_2018_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function to call the Wikimedia ORES API to get the quality ratings of each article. The code below is taken from the course instructor Jonathan Morgan's github page in the link below:\n",
    "\n",
    "https://github.com/Ironholds/data-512-a2/blob/master/hcds-a2-bias_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to call ORES API. API limit is ~290, so the rev_ids must be split into smaller chunks.\n",
    "headers = {'User-Agent' : 'https://github.com/ryanbae89',\n",
    "           'From' : 'rbae@uw.edu'}\n",
    "\n",
    "def get_ores_data(revision_ids, headers):\n",
    "    \n",
    "    # Define the endpoint\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/{project}/?models={model}&revids={revids}'\n",
    "    \n",
    "    # Specify the parameters - smushing all the revision IDs together separated by | marks.\n",
    "    # Yes, 'smush' is a technical term, trust me I'm a scientist.\n",
    "    # What do you mean \"but people trusting scientists regularly goes horribly wrong\" who taught you tha- oh.  \n",
    "    params = {'project' : 'enwiki',\n",
    "              'model'   : 'wp10',\n",
    "              'revids'  : '|'.join(str(x) for x in revision_ids)\n",
    "              }\n",
    "    api_call = requests.get(endpoint.format(**params))\n",
    "    response = api_call.json()\n",
    "#     print(json.dumps(response, indent=4, sort_keys=True))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get ORES scores for each article\n",
    "# get_ores_data must be called in chunks due to API limits\n",
    "rev_ids_full = list(page_data['rev_id'])\n",
    "n = 100\n",
    "rev_ids_chunks = [rev_ids_full[i:i+n] for i in range(0, len(rev_ids_full), n)]\n",
    "ores_ratings = []\n",
    "\n",
    "for rev_ids in rev_ids_chunks:\n",
    "    ores_results = get_ores_data(rev_ids, headers)\n",
    "    ores_ratings.append(ores_results['enwiki'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn to pandas dataframes and concatenate each chunk\n",
    "ores = pd.DataFrame()\n",
    "for ores_ratings_chunk in ores_ratings:\n",
    "    ores_chunk = pd.DataFrame.from_dict(ores_ratings_chunk['scores'], orient='index')\n",
    "    ores = pd.concat([ores, ores_chunk])\n",
    "ores = ores.reset_index()\n",
    "ores.columns = ['rev_id', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to get the prediction\n",
    "def get_pred(row):\n",
    "    if 'score' in row.keys():\n",
    "        return row['score']['prediction']\n",
    "    else:\n",
    "        return 'NaN'\n",
    "\n",
    "# apply to every row in the ores dataframe\n",
    "ores['prediction'] = ores['score'].apply(lambda x: get_pred(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 tensorflow",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
